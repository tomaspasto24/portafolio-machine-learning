<!doctype html>
<html lang="zxx">

<head>
    <title>Portafolio Tomás Silva</title>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="description" content="" />
    <meta name="keywords" content=" " />
    <meta name="developer" content="Tomás Silva">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- FAV AND ICONS   -->
    <link rel="shortcut icon" href="../assets/images/favicon.ico">
    <link rel="shortcut icon" href="../assets/images/apple-icon.png">
    <link rel="shortcut icon" sizes="72x72" href="../assets/images/apple-icon-72x72.png">
    <link rel="shortcut icon" sizes="114x114" href="../assets/images/apple-icon-114x114.png">

    <!-- Font-->
    <link href="https://fonts.googleapis.com/css?family=Roboto&display=swap" rel="stylesheet">
    <!-- Font Awesome -->
    <link rel="stylesheet" href="../assets/icons/font-awesome-4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../assets/icofont/icofont.min.css">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="../assets/plugins/css/bootstrap.min.css">
    <!-- Owl Carousel CSS-->
    <link rel="stylesheet" href="../assets/plugins/css/owl.css">
    <!-- Fancybox-->
    <link rel="stylesheet" href="../assets/plugins/css/jquery.fancybox.min.css">
    <!-- Anime CSS-->
    <link rel="stylesheet" href="../assets/plugins/css/revealer.css">
    <!-- Aos CSS-->
    <link rel="stylesheet" href="../assets/plugins/css/aos.css">
    <!-- Animate CSS-->
    <link rel="stylesheet" href="../assets/plugins/css/animate.css">
    <!-- Custom CSS-->
    <link rel="stylesheet" href="../assets/css/styles.css">
    <!-- Responsive -->
    <link rel="stylesheet" href="../assets/css/responsive.css">


</head>

<body class="black-bg body-2">
    <!--
    ===================
        NAVIGATION
    ===================
    -->
    <header class="black-bg mh-header nav-scroll fixed-top mh-xss-mobile-nav" id="zb-header">
        <div class="overlay"></div>
        <div class="container">
            <div class="row">
                <nav class="navbar navbar-expand-lg mh-nav nav-btn">
                    <a class="navbar-brand" href="index.html"><img src="../assets/images/logo.svg" alt=""
                            class="img-fluid"></a>
                    <button class="navbar-toggler" type="button" data-toggle="collapse"
                        data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                        aria-expanded="false" aria-label="Toggle navigation">
                        <span class="navbar-toggler-icon icon">
                            <i class="fa fa-bars"></i>
                        </span>
                    </button>
                    <div class="collapse navbar-collapse" id="navbarSupportedContent">
                        <ul class="navbar-nav mr-0 ml-auto">
                            <li class="nav-item">
                                <a class="nav-link" href="../index.html">Inicio</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="./index.html">Marco teórico</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="../ejercicios/index.html">Algoritmos</a>
                            </li>
                            <li class="nav-item">
                                <a class="nav-link" href="../casos-estudio/index.html">Casos de estudio</a>
                            </li>
                        </ul>
                    </div>
                </nav>
            </div>
        </div>
    </header>
    <section class="section relative portfolio-home">
        <div class="container">
            <div class="row">
                <div class="col-md-7 mx-auto">
                    <div class="portfolio-title wow fadeInUp" data-wow-duration=".9s" data-wow-delay=".1s">
                        <h1>Algoritmos No Lineales - Naive Bayes, K-NN y Feature Selection </h1>
                        <span></span>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section class="ag-blog-single-page">
        <div class="container">
            <div class="row section-separator vertical-middle-content ev-home-padding pb-0">
                <div class="col-sm-12 col-md-10">
                    <div class="ag-blog-post-content">
                        <div class="bl_img" id="rev-1">
                            <img src="../assets/images/nolineal.png" alt="" class="img-fluid">
                        </div>
                        <h5>
                            Eager learner
                        </h5>
                        <p>
                            Estos algoritmos contruyen un modelo predictivo desde el principio. Procesan los datos de
                            inmediato y crean un modelo antes de ver los datos de prueba. Ejemplo: árbol de decisión y
                            redes neuronales.
                        </p>

                        <h5>
                            Lazy learner
                        </h5>
                        <p>
                            Estos algoritmos no construyen un modelo de inmediato con los datos de entrenamiento, sino
                            que almacenan los datos de entrenamiento y esperan hasta que se les presente una consulta o
                            dato de prueba antes de realizar cualquier proceso de aprendizaje. Los lazy learners pueden
                            ser menos costosos en términos de tiempo de entrenamiento, pero pueden requerir más tiempo
                            en tiempo de consulta o inferencia.
                        </p>

                        <h5>
                            k-NEAREST NEIGHBORS
                        </h5>
                        <p>
                            Es un algoritmo de aprendizaje supervisado, utilizado para clasificación y regresión.
                            Clasifica o predice un punto de datos basándose en la mayoría de los puntos de datos más
                            cercanos a él en un espacio multidimensional.

                            Efectivo, cuando se tiene un conjunto de datos pequeño o cuando no se sabe mucho sobre la
                            estructura subyacente de los datos.
                        </p>

                        <div class="bl_img" id="rev-2">
                            <img src="../assets/images/no-lineal-1.png" alt="" class="img-fluid">
                        </div>

                        <p>
                            Si se pone k = 1, iria a buscar el vecino más cercano, este puede ser un outlier, por lo
                            tanto. En cambio k = 3, buscaría los 3 vecinos más cercanos y los haría votar. Como es una
                            votación, se ponen k números impares.
                        </p>

                        <div class="bl_img" id="rev-2">
                            <img src="../assets/images/no-lineal-2.png" alt="" class="img-fluid">
                        </div>

                        <p>
                            La efectividad de k-NN es determinada por qué tan diferente es el dataset de prueba con el
                            dataset de entrenamiento. Para ver esto hay tecnicas, como jaccard, la similitud de coseno,
                            calculo de distancia y correlación.

                            Todas las entradas de k-NN se normalizan, donde los valores de los datos se reescalan para
                            adaptarse a un rango particular. Esto se hace en todos los algoritmos de distancias.

                            <strong>Distancia Euclideana →</strong> es la más común, basada en el teorema de
                            Pitágoras. Distancia entre dos puntos en espacio multidimensional.

                            <strong>Distancia Manhattan →</strong> En lugar de calcular la distancia en línea recta
                            entre dos puntos,
                            como lo hace la distancia euclidiana, la distancia Manhattan calcula la distancia siguiendo
                            caminos en forma de cuadrícula (como las manzanas de una ciudad). Esta distancia es útil
                            cuando se quiere medir la distancia en términos de movimientos horizontales y verticales,
                            como en una ciudad con calles perpendiculares.

                            <strong>Distancia Chebyshev →</strong> Esta distancia se calcula considerando la máxima
                            diferencia entre
                            las coordenadas de dos puntos en cada dimensión.
                        </p>

                        <div class="bl_img" id="rev-2">
                            <img src="../assets/images/no-lineal-3.png" alt="" class="img-fluid">
                        </div>

                        <p>
                            El modelo k-NN (k-Vecinos Más Cercanos) requiere <strong>normalización<strong> para evitar sesgos
                            causados por atributos que tienen unidades grandes o pequeñas en la escala. El modelo es
                            bastante robusto cuando faltan valores en los atributos de prueba. Si falta un valor en el
                            registro de prueba, se ignora todo el atributo en el modelo y el modelo aún puede funcionar
                            con precisión razonable. Por ejemplo, si no se conoce la longitud del sépalo en un registro
                            de prueba, entonces se ignora la longitud del sépalo en el modelo, convirtiendo al k-NN en
                            un modelo tridimensional en lugar de cuatro dimensiones originales.

                            Como aprendiz "perezoso", la relación entre la entrada y la salida no puede explicarse, ya
                            que el modelo es simplemente un conjunto memorizado de todos los registros de entrenamiento.
                            No hay generalización ni abstracción de la relación. Los aprendices "ávidos" son mejores
                            para explicar la relación y proporcionar una descripción del modelo.

                            La construcción del modelo en k-NN consiste principalmente en memorizar y no requiere mucho
                            tiempo. Sin embargo, cuando se va a clasificar un nuevo registro sin etiquetar, el algoritmo
                            debe calcular la distancia entre el registro no visto y todos los registros de
                            entrenamiento. Este proceso puede ser costoso, según el tamaño del conjunto de entrenamiento
                            y el número de atributos. Algunas implementaciones avanzadas de k-NN indexan los registros
                            para que sea fácil buscar y calcular la distancia. También se pueden convertir los números
                            reales en rangos para facilitar la indexación y la comparación con el registro de prueba.
                            Sin embargo, k-NN no es adecuado para aplicaciones sensibles al tiempo, como servir
                            publicidad en línea o detección de fraudes en tiempo real.

                            Los modelos k-NN pueden manejar entradas categóricas, pero la medida de distancia será 1 o
                            0. Los valores ordinales se pueden convertir a números enteros para aprovechar mejor la
                            función de distancia. Aunque el modelo k-NN no es bueno para generalizar la relación entre
                            entrada y salida, sigue siendo bastante efectivo y aprovecha las relaciones existentes entre
                            atributos y etiquetas de clase en los registros de entrenamiento. Para obtener resultados de
                            alta calidad, requiere un número significativo de registros de entrenamiento con el máximo
                            número posible de valores de permutación en los atributos de entrada.
                        </p>

                        <h5>
                            Naive Bayes
                        </h5>

                        <p>
                            Es un algoritmo de aprendizaje supervisado, se utiliza principalmente para clasificación,
                            útil para trabajar con texto o datos categóricos (por ejemplo “spam” “no spam”). El
                            algoritmo hace una suposición de independencia entre atributos. La suposición de
                            independencia entre atributos puede no ser siempre cierta.

                            La probabilidad a priori es una estimación inicial de la probabilidad de un evento antes de
                            observar datos adicionales, mientras que la probabilidad a posteriori es la probabilidad
                            actualizada de que ocurra el evento después de tener en cuenta nueva evidencia. El teorema
                            de Bayes proporciona una herramienta matemática para calcular la probabilidad a posteriori a
                            partir de la probabilidad a priori y la evidencia observada, y es fundamental en
                            estadísticas y aprendizaje automático para actualizar creencias y tomar decisiones
                            informadas.
                        </p>

                        <div class="bl_img" id="rev-2">
                            <img src="../assets/images/no-lineal-4.png" alt="" class="img-fluid">
                        </div>

                        <p>
                            A no tiene que ocurrir antes que B.

                            P (A | B) = probabilidad de a siendo b verdadero
                        </p>

                        <div class="bl_img" id="rev-2">
                            <img src="../assets/images/no-lineal-5.png" alt="" class="img-fluid">
                        </div>

                        <p>
                            Se le llama ingenuo porque suponemos que la clase de los datos x son independientes de otros
                            valores para la clase c.
                        </p>

                        <div class="bl_img" id="rev-2">
                            <img src="../assets/images/no-lineal-6.png" alt="" class="img-fluid">
                        </div>
                        <div class="bl_img" id="rev-2">
                            <img src="../assets/images/no-lineal-7.png" alt="" class="img-fluid">
                        </div>

                        <h5>
                            Feature Selection
                        </h5>

                        <p>
                            Feature Selection es un proceso importante en el análisis de datos y el aprendizaje
                            automático que consiste en elegir un subconjunto relevante y significativo de
                            características o atributos de un conjunto de datos más grande. El objetivo principal de la
                            selección de características es mejorar el rendimiento de los modelos de aprendizaje
                            automático y simplificar la interpretación de los datos. Aquí te explico más sobre este
                            proceso:
                        </p>

                        <h5>
                            Importancia de la Selección de Características:
                        </h5>

                        <p>
                            1. <strong>Mejora del rendimiento:</strong> Al reducir el número de características, se pueden eliminar
                            características irrelevantes o redundantes que pueden estar afectando negativamente el
                            rendimiento del modelo. Esto puede llevar a modelos más simples y eficientes.
                            2. <strong>Reducción del sobreajuste:</strong> La selección de características puede ayudar a prevenir el
                            sobreajuste, que ocurre cuando un modelo es demasiado complejo y se ajusta demasiado a los
                            datos de entrenamiento, perdiendo la capacidad de generalizar a nuevos datos.
                            3. <strong>Ahorro de recursos:</strong> Al utilizar solo las características más importantes, se reduce
                            la cantidad de datos necesarios para entrenar y aplicar modelos, lo que ahorra tiempo y
                            recursos computacionales.
                        </p>

                        <h5>
                            Métodos de Selección de Características:
                        </h5>

                        <p>
                            Existen varios métodos para llevar a cabo la selección de características, que se pueden
                            dividir en tres categorías principales:

                            1. <strong>Métodos de Filtro:</strong> Estos métodos evalúan la relevancia de cada característica de
                            forma independiente de cualquier modelo de aprendizaje automático. Se utilizan medidas
                            estadísticas, como la correlación o la prueba chi-cuadrado, para clasificar las
                            características según su importancia y luego se selecciona un subconjunto en función de
                            cierto umbral.
                            2. <strong>Métodos de Envoltura:</strong> En estos métodos, se utiliza un modelo de aprendizaje
                            automático para evaluar la calidad de diferentes subconjuntos de características. Se prueban
                            diferentes combinaciones de características y se selecciona la que mejora el rendimiento del
                            modelo según una métrica específica, como la precisión o el error cuadrático medio.
                            3. <strong>Métodos Integrados:</strong> Estos métodos incorporan la selección de características como
                            parte del proceso de entrenamiento del modelo mismo. Ejemplos incluyen algoritmos como LASSO
                            (Least Absolute Shrinkage and Selection Operator) y Ridge Regression, que penalizan
                            automáticamente las características menos relevantes durante el entrenamiento.
                        </p>

                        <h5>
                            Consideraciones Importantes:
                        </h5>

                        <p>
                            - La elección del método de selección de características depende del problema y del tipo de
                            datos. No existe un enfoque único que funcione para todos los casos.
                            - Es importante evaluar el impacto de la selección de características en el rendimiento del
                            modelo mediante validación cruzada u otras técnicas de evaluación.
                            - La selección de características puede llevar a una pérdida de información si se eliminan
                            características relevantes, por lo que se debe realizar con cuidado.

                            En resumen, la selección de características es un paso esencial en la preparación de datos y
                            la construcción de modelos de aprendizaje automático. Ayuda a mejorar la eficiencia y la
                            precisión de los modelos al elegir las características más relevantes y eliminar el ruido,
                            lo que facilita la interpretación y la toma de decisiones basadas en datos.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </section>

    <script src="../assets/plugins/js/jquery.min.js"></script>
    <!-- popper -->
    <script src="../assets/plugins/js/popper.min.js"></script>
    <!-- bootstrap -->
    <script src="../assets/plugins/js/bootstrap.min.js"></script>
    <!-- waypoint  -->
    <script src="../assets/plugins/js/waypoints.min.js"></script>
    <!-- owl carousel -->
    <script src="../assets/plugins/js/owl.carousel.js"></script>
    <!-- validator -->
    <script src="../assets/plugins/js/validator.min.js"></script>
    <!-- wow -->
    <script src="../assets/plugins/js/wow.min.js"></script>
    <!-- jquery nav -->
    <script src="../assets/plugins/js/jquery.nav.js"></script>
    <!-- Isotop -->
    <script src="../assets/plugins/js/isotope.pkgd.js"></script>
    <script src="../assets/plugins/js/packery-mode.pkgd.js"></script>
    <!-- Fancybox js-->
    <script src="../assets/plugins/js/jquery.fancybox.min.js"></script>
    <!-- AOS  -->
    <script src="../assets/plugins/js/aos.js"></script>
    <script src="../assets/plugins/js/wow.min.js"></script>
    <script src="../assets/plugins/js/TweenMax.min.js"></script>
    <!-- Parallax -->
    <script src="../assets/plugins/js/simpleParallax.min.js"></script>
    <!-- <script src="../assets/plugins/js/typed.js"></script> -->
    <!-- Scroll Effect -->
    <script src="../assets/plugins/js/anime.min.js"></script>
    <script src="../assets/plugins/js/scrollMonitor.js"></script>
    <script src="../assets/plugins/js/scroll-effect.js"></script>
    <!-- Custom Scripts-->
    <script src="../assets/js/custom-scripts.js"></script>
    <script>
        new WOW().init();
    </script>
</body>

</html>